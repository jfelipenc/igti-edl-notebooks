{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho IGTI Fashion MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P22A4e2pu53Z"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential     #importa modelo Sequential\n",
        "from keras.applications import vgg16    #importa rede VGG16\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import InputLayer, Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WMd6YG5vg1R",
        "outputId": "3471ed4a-097c-4b9d-e623-7f3cc7a29337"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xpp90bzEvuhX",
        "outputId": "b1d4963f-1b5e-48a8-ac27-d7cd7873b01d"
      },
      "source": [
        "# mostra uma determinada imagem da rede\n",
        "def show_img(element):\n",
        "  img = np.array(element, dtype='float')\n",
        "  img = img.reshape((28,28))\n",
        "  plt.imshow(img, cmap='gray')\n",
        "\n",
        "show_img(X_train[4000])\n",
        "print(y_train[4000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Meq9F1wjpd",
        "outputId": "dee8d443-2165-4d02-c856-db1627207f96"
      },
      "source": [
        "# define algumas variáveis úteis, normaliza conjunto de treino e transforma y's em categóricos\n",
        "total_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "\n",
        "X_train_32f = X_train / 255\n",
        "X_train_32f = X_train_32f.reshape(X_train_32f.shape[0], total_pixels).astype('float32')\n",
        "print(X_train.shape)\n",
        "X_test_32f  = X_test / 255\n",
        "X_test_32f = X_test_32f.reshape(X_test_32f.shape[0], total_pixels).astype('float32')\n",
        "\n",
        "y_train_cat = np_utils.to_categorical(y_train)\n",
        "y_test_cat = np_utils.to_categorical(y_test)\n",
        "\n",
        "num_classes  = len(y_train_cat[0])\n",
        "\n",
        "print(\"Number of pixels: \", total_pixels, \"\\nNumber of classes: \", num_classes, \"\\nShape of Train Data: \", X_train_32f.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Number of pixels:  784 \n",
            "Number of classes:  10 \n",
            "Shape of Train Data:  (60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwZjmjhBBxXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61784276-48a0-43c7-d7b5-0d2d63c51ea0"
      },
      "source": [
        "y_train_cat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K6WFIR1wM7w",
        "outputId": "4e66b606-41a7-4f4e-814a-1d3380c0f561"
      },
      "source": [
        "# cria a segunda rede descrita no enunciado\n",
        "\n",
        "std_model = Sequential()\n",
        "std_model.add(InputLayer(input_shape=total_pixels))\n",
        "std_model.add(Dense(total_pixels, activation='relu', kernel_initializer='normal'))\n",
        "std_model.add(Dense(1024, activation='relu', kernel_initializer='normal'))\n",
        "std_model.add(Dense(2048, activation='relu', kernel_initializer='normal'))\n",
        "std_model.add(Dense(2048, activation='relu', kernel_initializer='normal'))\n",
        "std_model.add(Dense(num_classes, activation='softmax', kernel_initializer='normal'))\n",
        "std_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 7,735,322\n",
            "Trainable params: 7,735,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfFKNXaaxycB"
      },
      "source": [
        "std_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGWlyKumyObV",
        "outputId": "34bdd64f-b027-4b8e-c9c1-e649c0d04f75"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=-3, patience=3, verbose=2, restore_best_weights=True)\n",
        "modelcheck = ModelCheckpoint('/content/model_igti_{epoch:02d}.h5', monitor='val_loss', verbose=2)\n",
        "\n",
        "result_std = std_model.fit(X_train_32f, y_train_cat, batch_size=100, epochs=20, verbose=1, validation_data=(X_test_32f, y_test_cat), callbacks=[earlystop, modelcheck])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2084 - accuracy: 0.9209 - val_loss: 0.3585 - val_accuracy: 0.8866\n",
            "\n",
            "Epoch 00001: saving model to /content/model_igti_01.h5\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1999 - accuracy: 0.9231 - val_loss: 0.3570 - val_accuracy: 0.8839\n",
            "\n",
            "Epoch 00002: saving model to /content/model_igti_02.h5\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1954 - accuracy: 0.9258 - val_loss: 0.3404 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 00003: saving model to /content/model_igti_03.h5\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1869 - accuracy: 0.9297 - val_loss: 0.3630 - val_accuracy: 0.8929\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00004: saving model to /content/model_igti_04.h5\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwVwbq2VCAQS",
        "outputId": "0da29e40-51e5-4f45-a1cf-7a424f674017"
      },
      "source": [
        "from tensorflow.image import resize\n",
        "\n",
        "X_train_res = np.expand_dims(X_train, axis=-1)\n",
        "X_train_res = np.repeat(X_train_res, 3, axis=-1)\n",
        "X_train_res = resize(X_train_res, [32,32])\n",
        "X_train_res.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 32, 32, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPb6tqnmC8kR",
        "outputId": "c864ba04-787c-4d64-ea3c-8833bebc32e6"
      },
      "source": [
        "X_test_res = np.expand_dims(X_test, axis=-1)\n",
        "X_test_res = np.repeat(X_test_res, 3, axis=-1)\n",
        "X_test_res = resize(X_test_res, [32,32])\n",
        "\n",
        "\n",
        "X_test_res.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10000, 32, 32, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQEtkTIgyiaB",
        "outputId": "2a4e3748-7540-40af-aa2b-133bfff0a129"
      },
      "source": [
        "# cria a rede vgg-16 do enunciado\n",
        "\n",
        "model_vgg_2 = vgg16.VGG16(include_top=True, classes=10, input_shape=(32,32,3), weights=None)\n",
        "model_vgg_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
        "model_vgg_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 33,638,218\n",
            "Trainable params: 33,638,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEQhGje3_iZQ",
        "outputId": "35f38336-1375-49e1-d092-6c8f967f5912"
      },
      "source": [
        "earlystop_vgg = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, restore_best_weights=True)\n",
        "\n",
        "model_vgg_2.fit(X_train_res, y_train_cat, batch_size=128, epochs=3, verbose=1, validation_data=(X_test_res, y_test_cat), callbacks=[earlystop_vgg])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "469/469 [==============================] - 30s 61ms/step - loss: 1.9618 - accuracy: 0.4245 - val_loss: 0.4465 - val_accuracy: 0.8371\n",
            "Epoch 2/3\n",
            "469/469 [==============================] - 28s 61ms/step - loss: 0.4204 - accuracy: 0.8523 - val_loss: 0.3531 - val_accuracy: 0.8786\n",
            "Epoch 3/3\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 0.3171 - accuracy: 0.8863 - val_loss: 0.4158 - val_accuracy: 0.8569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7430db0cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdL8tz2jDNP9"
      },
      "source": [
        "def predict(model, element):\n",
        "  el = np.expand_dims(element, axis=0)\n",
        "  print(np.argmax(model.predict(el)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4x48cgdy4IO"
      },
      "source": [
        "for x in X_test_res[:100]:\n",
        "  predict(model_vgg_2, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNDZM6_6fQb_"
      },
      "source": [
        "norm_weights = model_vgg_2.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx3Jci9jgTyk"
      },
      "source": [
        "unnorm_weights = model_vgg_2.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrC4s9Xfhia8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}